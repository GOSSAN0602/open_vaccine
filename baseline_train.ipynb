{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 10\n",
    "BATCH_SIZE = 256\n",
    "LEARN_RATE = 0.001\n",
    "FEATURE_SIZE = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(categories, string):\n",
    "    encoding = np.zeros((len(string), len(categories)))\n",
    "    for idx, char in enumerate(string):\n",
    "        encoding[idx, categories.index(char)] = 1\n",
    "    return encoding\n",
    "\n",
    "def featurize(entity):\n",
    "    sequence = one_hot(list('ACGU'), entity['sequence'])\n",
    "    structure = one_hot(list('.()'), entity['structure'])\n",
    "    loop_type = one_hot(list('BEHIMSX'), entity['predicted_loop_type'])\n",
    "    features = np.hstack([sequence, structure, loop_type])\n",
    "    return features \n",
    "\n",
    "def char_encode(index, features, feature_size):\n",
    "    half_size = (feature_size - 1) // 2\n",
    "    \n",
    "    if index - half_size < 0:\n",
    "        char_features = features[:index+half_size+1]\n",
    "        padding = np.zeros((int(half_size - index), char_features.shape[1]))\n",
    "        char_features = np.vstack([padding, char_features])\n",
    "    elif index + half_size + 1 > len(features):\n",
    "        char_features = features[index-half_size:]\n",
    "        padding = np.zeros((int(half_size - (len(features) - index))+1, char_features.shape[1]))\n",
    "        char_features = np.vstack([char_features, padding])\n",
    "    else:\n",
    "        char_features = features[index-half_size:index+half_size+1]\n",
    "    \n",
    "    return char_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaxDataset(Dataset):\n",
    "    def __init__(self, path, test=False):\n",
    "        self.path = path\n",
    "        self.test = test\n",
    "        self.features = []\n",
    "        self.targets = []\n",
    "        self.ids = []\n",
    "        self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        with open(self.path, 'r') as text:\n",
    "            for line in text:\n",
    "                records = json.loads(line)\n",
    "                features = featurize(records)\n",
    "                \n",
    "                for char_i in range(records['seq_scored']):\n",
    "                    char_features = char_encode(char_i, features, FEATURE_SIZE)\n",
    "                    self.features.append(char_features)\n",
    "                    self.ids.append('%s_%d' % (records['id'], char_i))\n",
    "                        \n",
    "                if not self.test:\n",
    "                    targets = np.stack([records['reactivity'], records['deg_Mg_pH10'], records['deg_Mg_50C']], axis=1)\n",
    "                    self.targets.extend([targets[char_i] for char_i in range(records['seq_scored'])])\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.test:\n",
    "            return self.features[index], self.ids[index]\n",
    "        else:\n",
    "            return self.features[index], self.targets[index], self.ids[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VaxDataset('../input/stanford-covid-vaccine/train.json')\n",
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.view(batch_size, -1)\n",
    "\n",
    "class VaxModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VaxModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv1d(14, 32, 1, 1),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv1d(32, 1, 1, 1),\n",
    "            nn.PReLU(),\n",
    "            Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(FEATURE_SIZE, 32),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 3),\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        return self.layers(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VaxModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), LEARN_RATE)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6041340827941895\n",
      "1 0.5405337810516357\n",
      "2 0.5353986024856567\n",
      "3 0.5316371321678162\n",
      "4 0.5288143157958984\n",
      "5 0.526353657245636\n",
      "6 0.524962842464447\n",
      "7 0.524658203125\n",
      "8 0.5235721468925476\n",
      "9 0.5217710733413696\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCH):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    for features, targets, ids in train_dataloader:\n",
    "        features = features.permute(0,2,1).float()\n",
    "        targets = targets.float()\n",
    "        predictions = model(features)\n",
    "        loss = criterion(predictions, targets)\n",
    "        for p in model.parameters():\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().numpy())\n",
    "    avg_loss = float(np.mean(losses))\n",
    "    print(epoch, avg_loss)\n",
    "\n",
    "torch.save(model.state_dict(), './weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
